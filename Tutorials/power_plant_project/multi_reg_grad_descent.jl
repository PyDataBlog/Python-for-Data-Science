# Import needed libraries
using Plots
using XLSX
using DataFrames
using Statistics


# Read the relevant excel workbook
df = DataFrames.DataFrame(XLSX.readtable("Folds5x2_pp.xlsx", "Sheet5")...)

# Split into design matrix and target vector
X = df[:, 1:4]
design_matrix = convert(Matrix, X)

y = df[:, 5]  # Target vector

# Split into training and test
train_size = 0.80
data_size = size(design_matrix)[1]

train_index = trunc(Int, train_size * data_size)

# Split using the desired train size
X_train = design_matrix[1:train_index, :]
X_test = design_matrix[train_index+1:end, :]

y_train = y[1:train_index]
y_test = y[train_index+1:end]


"""
    scale_features(X)

This function attempts to normalise the design matrix (X) user pass.
The input data X is standardised and return along with other learned metrics.

A tuple with 3 elements is returned representing (Standardised data, mean, std deviation).

"""
function scale_features(X)

    Î¼ = mean(X, dims=1)
    Ïƒ = std(X, dims=1)

    X_norm = (X .- Î¼) ./ Ïƒ

    return (X_norm, Î¼, Ïƒ)
end


"""
    transform_features(X, Î¼, Ïƒ)

This functions uses the mean and standard deviation values users pass to
normalise a new design matrix.
"""
function transform_features(X, Î¼, Ïƒ)
    X_norm = (X .- Î¼) ./ Ïƒ
    return X_norm
end

# Scale training features and get artificats for future use
X_train_scaled, Î¼, Ïƒ = scale_features(X_train)

# Transform the testing features by using the learned artifacts
X_test_scaled = transform_features(X_test, Î¼, Ïƒ)


"""
    mean_squared_cost(X, y, Î¸)

This function computes the batch cost based on the values of the design matrix (X),
target vector (y), and the weights (Î¸) passed to it.
"""
function mean_squared_cost(X, y, Î¸)
    # Sample size
    m = size(X)[1]

    # Vectorised Prediction loss
    preds = X * Î¸
    loss = preds - y

    # Half mean squared loss
    cost =  (1/(2m)) * (loss' * loss)

    return cost
end


"""
    lin_reg_grad_descent(X, y, Î±, fit_intercept=true, n_iter=1000)

This function uses gradient descent algorithm to find the best weights (Î¸)
that minimises the mean squared loss between the predictions that the model
generates and the target vector (y).

A tuple of 1D vectors representing the weights (Î¸)
and a history of loss at each iteration (ğ‰) is returned.
"""
function lin_reg_grad_descent(X, y, Î±, fit_intercept=true, n_iter=2000)
    # Initialize some useful values
    m = length(y) # number of training examples

    if fit_intercept
        # Add a constant of 1s if fit_intercept is specified
        constant = ones(m, 1)
        X = hcat(constant, X)
    else
        X # Assume user added constants
    end

    # Use the number of features to initialise the theta Î¸ vector
    n = size(X)[2]
    Î¸ = zeros(n)

    # Initialise the cost vector based on the number of iterations
    ğ‰ = zeros(n_iter)

    for iter in range(1, stop=n_iter)
        pred = X * Î¸

        # Calcaluate the cost for each iter
        ğ‰[iter] = mean_squared_cost(X, y, Î¸)

        # Update the theta Î¸ at each iter
        Î¸ = Î¸ - ((Î±/m) * X') * (pred - y);
    end
    return (Î¸, ğ‰)
end


Î¸, ğ‰ = lin_reg_grad_descent(X_train_scaled, y_train, 0.05, true, 3000)

plot(ğ‰,
     label="Cost per iter",
     ylabel="Cost",
     xlabel="Number of Iteration",
     title="Cost Per Iteration")

savefig("cost_plot")

"""
    predict(X, Î¸, fit_intercept=true)

This function uses the learned weights (Î¸) to make predictions based on the
design matrix passed as (X).

The 1D vector representing these predictions is finally returned.
"""
function predict(X, Î¸, fit_intercept=true)
    m = size(X)[1]

    if fit_intercept
        constant = ones(m)
        X = hcat(constant, X)
    else
        X
    end

    predictions = X * Î¸

    return predictions
end


# Make predictions for both training and testing datasets
train_preds = predict(X_train_scaled, Î¸)
test_preds = predict(X_test_scaled, Î¸)



"""
    rmse_score(y_true, y_pred)

This function calculates the RMSE based on the values of ground truth (y_true)
and the predicted values generated by a model (y_pred)
"""
function rmse_score(y_true, y_pred)

    errors = y_pred - y_true
    errorsÂ² = errors .^ 2
    mse = mean(errorsÂ²)
    rmse = sqrt(mse)

    return rmse

end


println("RMSE for Training Set: ", rmse_score(y_train, train_preds))
println("RMSE for Testing Set: ", rmse_score(y_test, test_preds))



"""
    r_squared_score(y_pred, y_true)

This function returns the R squared value based on the predictions (y_pred)
and the ground truth values (y_true)passed to it.
"""
function r_squared_score(y_pred, y_true)
    # Just a convinient way of using notations
    âˆ‘ = sum
    Î¼ = mean

    # Compute sum of explained variance (SST) and sum of squares of residuals
    sst = âˆ‘(((y_true .- Î¼(y_true)) .^ 2))
    ssr = âˆ‘(((y_pred .- y_true) .^ 2))

    rÂ² = 1 - (ssr / sst)

    return rÂ²
end


# Get the r-squared score for training and test datasets
train_rÂ² = r_squared_score(train_preds, y_train)
test_rÂ² = r_squared_score(test_preds, y_test)


println("Training RÂ² score for test sets: ", train_rÂ²)
println("Testing RÂ² score for test sets: ", test_rÂ²)
